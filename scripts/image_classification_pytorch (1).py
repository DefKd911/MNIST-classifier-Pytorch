# -*- coding: utf-8 -*-
"""Image Classification-Pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iY-zKOa4ngopVXTk1QQBIt2_ieLBOKK5
"""

import torch
import torchvision
from torchvision.datasets import MNIST

import numpy as np

dataset=MNIST(root='data/',download=True)

len(dataset)

test=MNIST('data/',train=False)

len(test)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

image,label=dataset[0]
plt.imshow(image,cmap='gray')
print('Label:',label)

image,label=dataset[3]
plt.imshow(image,cmap='gray')
print('Label:',label)

import torchvision.transforms as transforms

dataset=MNIST('data1/',train=True,transform=transforms.ToTensor(),download=True)

""" We'll use the ToTensor transform to convert images into PyTorch tensors."""

img_tensor,label=dataset[0]
print(img_tensor.shape,label)
# The image is now converted to a 1x28x28 tensor. The first dimension tracks color channels.
# The second and third dimensions represent pixels along the height and width of the image, respectively

print(print(img_tensor[0,10:15,10:15]))
print(torch.max(img_tensor),torch.min(img_tensor))

plt.imshow(img_tensor[0,10:15,10:15],cmap='gray')
# The values range from 0 to 1, with 0 representing black, 1 white,
#  and the values in between different shades of grey.
# We can also plot the tensor as an image using plt.imshow.

from torch.utils.data import random_split

# training validation datasets
train_ds,val_ds=torch.utils.data.random_split(dataset,[50000,10000])
len(train_ds),len(val_ds)

from torch.utils.data import DataLoader # DataLoader class name is case-sensitive
batch_size=128
train_dl=DataLoader(train_ds,batch_size,shuffle=True)
val_dl=DataLoader(val_ds,batch_size,shuffle=True)

"""#
A logistic regression model is almost identical to a linear regression model. It contains weights and bias matrices, and the output is obtained using simple matrix operations (pred = x @ w.t() + b).

As we did with linear regression, we can use nn.Linear to create the model instead of manually creating and initializing the matrices.

Since nn.Linear expects each training example to be a vector, each 1x28x28 image tensor is flattened into a vector of size 784 (28*28) before being passed into the model.

The output for each image is a vector of size 10, with each element signifying the probability of a particular target label (i.e., 0 to 9). The predicted label for an image is simply the one with the highest probability.


"""

img,label=dataset[0]

import torch.nn as nn
input_size=28*28
n_class=10
model=nn.Linear(input_size,n_class)

print(model.weight)
print(model.bias)

imgs.shape

for imgs,labels in train_dl:
    print(labels)
    print(imgs.shape)
    outputs=model(img)
    print(outputs)
    break

imgs.reshape(128,784).shape

class MnistModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.linear=nn.Linear(input_size,n_class)

  def forward(self,xb):
    xb=xb.reshape(-1,784)
    out=self.linear(xb)
    return out

# xb.reshape(-1, 28*28) indicates to PyTorch that we want a view of the xb
#  tensor with two dimensions.
# The length along the 2nd dimension is 28*28 (i.e., 784).
# One argument to .reshape can be set to -1 (in this case, the first dimension)
#  to let PyTorch figure it out automatically based on the shape of the original tensor.

model=MnistModel()

print(model.linear.weight.shape,model.linear.bias.shape)

for images,labels in train_dl:
  print(images.shape)
  output=model(images)
  break
print('output.shape',output.shape)
print('Sample outputs :\n',output[:2].data)

output[0]

import torch.nn.functional as F

probs=F.softmax(output,dim=1)
print(probs.data.shape)
print("Sum : ", torch.sum(probs[0]))

max_probs,preds=torch.max(probs,dim=1)
print(preds)
print(max_probs)
# torch.max, which returns each row's largest element and the corresponding index.

labels
# Most of the predicted labels are different from the actual labels.
#  That's because we have started with randomly initialized weights and biases.
#  We need to train the model, i.e., adjust the weights using gradient descent to make better predictions.

torch.sum(preds==labels)

len(preds)

def accuracy(outputs,labels):
  _,preds=torch.max(outputs,dim=1)
  return torch.sum(preds==labels).item()/len(preds)

# Note that we don't need to apply softmax to the outputs
#  since its results have the same relative order.
# This is because e^x is an increasing function, i.e., if y1 > y2,
#  then e^y1 > e^y2. The same holds after averaging out the values to get the softmax.

# Let's calculate the accuracy of the current model on the first batch of data.
accuracy(output,labels)

probs

loss_fn=F.cross_entropy

"""9"""

loss=loss_fn(output,labels)
print(loss)
# e. The lower the loss, The better the model.

# loss_batch function :
# -> calculates loss for batch of data
# -> optionally performs a G-D update steo if an optimizer is provided

def loss_batch(xb, yb, model, loss_fn, opt=None, metric=None):
    preds = model(xb)
    loss = loss_fn(preds, yb)
    if opt is not None:
        loss.backward()
        opt.step()
        opt.zero_grad()

    metric_result = None
    if metric is not None:
        metric_result = metric(preds, yb)
    return loss.item(), len(xb), metric_result

def evaluate(model,loss_fn,valid_dl,metric=None):
  with torch.no_grad():
    results= [loss_batch(xb, yb, model, loss_fn, metric=metric) for xb,yb in valid_dl]
    losses,nums,metrics=zip(*results)
    total=np.sum(nums)
    avg_loss=np.sum(np.multiply(losses,nums))/total
    avg_metric=None
    if metric is not None:
      avg_metric=np.sum(np.multiply(metrics,nums))/total
  return avg_loss,avg_metric

""" evaluating validation dataset"""

val_loss,val_acc=evaluate(model,loss_fn,val_dl,metric=accuracy)
print(val_loss,val_acc)

import matplotlib.pyplot as plt

def fit(epochs, model, loss_fn, opt, train_dl, valid_dl, metric=None):
    train_losses, train_metrics = [], []
    val_losses, val_metrics = [], []

    for epoch in range(epochs):
        # Training
        model.train()
        train_loss, train_metric = 0, 0
        for xb, yb in train_dl:
            loss, _, metric_result = loss_batch(xb, yb, model, loss_fn, opt, metric)
            train_loss += loss
            if metric_result is not None:
                train_metric += metric_result

        train_losses.append(train_loss / len(train_dl))
        if metric is not None:
            train_metrics.append(train_metric / len(train_dl))

        # Evaluation
        model.eval()
        val_loss, val_metric = evaluate(model, loss_fn, valid_dl, metric)
        val_losses.append(val_loss)
        if metric is not None:
            val_metrics.append(val_metric)

        # Printing
        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_loss:.4f}', end='')
        if metric is not None:
            print(f', Train {metric.__name__}: {train_metrics[-1]:.4f}, Val {metric.__name__}: {val_metric:.4f}')
        else:
            print()

    return train_losses, train_metrics, val_losses, val_metrics

# Run the training
train_losses, train_metrics, val_losses, val_metrics = fit(10, model, F.cross_entropy, optimizer, train_dl, val_dl, metric=accuracy)

# Plotting
plt.figure(figsize=(12, 4))

# Loss plot
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')

# Accuracy plot
plt.subplot(1, 2, 2)
plt.plot(train_metrics, label='Train Accuracy')
plt.plot(val_metrics, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.tight_layout()
plt.show()

def predict_image(img,model):
  xb=img.unsqueeze(0)
  yb=model(img)
  _,preds=torch.max(yb,dim=1)
  return preds[0].item()

img,label=dataset[3]
plt.imshow(img[0],cmap='gray')
print('Label:',label,'Predicted:',predict_image(img,model))

img,label=dataset[0]
plt.imshow(img[0],cmap='gray')
print('Label:',label,'Predicted:',predict_image(img,model))

"""# model is not able to capture Spatial Relationships"""

# need better and Complex Architecture to enhance accuracy

torch.save(model.state_dict(),'model.pth')

model.state_dict()

model2=MnistModel()
model2.load_state_dict(torch.load('model.pth'))
model2.state_dict()

